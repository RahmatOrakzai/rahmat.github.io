{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"proceedings.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED key0: \" Simulator for modeling, analysis, and visualizations of ther ... \"\n",
      "SUCESSFULLY PARSED key1: \" Parallel delay multiply and sum algorithm for microwave medi ... \"\n",
      "SUCESSFULLY PARSED key2: \" Measurement of whole-brain atrophy progression using microwa ... \"\n",
      "WARNING Missing Expected Field 'journal' from entry key3: \" A Simulator for Analysis, Mode ... \"\n",
      "SUCESSFULLY PARSED key4: \" Experimental radar data for monitoring brain atrophy progres ... \"\n",
      "SUCESSFULLY PARSED key5: \" Multi-skills resource constrained and personality traits bas ... \"\n",
      "SUCESSFULLY PARSED key6: \" An integrated methodology for bibliometric analysis: a case  ... \"\n",
      "SUCESSFULLY PARSED key7: \" Multistatic radar-based imaging in layered and dispersive me ... \"\n",
      "SUCESSFULLY PARSED key8: \" Microwave sensing dataset for noninvasive monitoring of vent ... \"\n",
      "SUCESSFULLY PARSED key9: \" A machine learning-based classification method for monitorin ... \"\n",
      "WARNING Missing Expected Field 'journal' from entry key10: \" Data-driven microwave imaging  ... \"\n",
      "SUCESSFULLY PARSED key11: \" Weighted multi-skill resource constrained project scheduling ... \"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../_publications/2024-01-01-Classification-of-skin-lesion-with-features-extraction-using-quantum-chebyshev-polynomials-and-autoencoder-from-wavelet-transformed-images.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    103\u001b[39m output_dir = \u001b[33m\"\u001b[39m\u001b[33m../_publications/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    104\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Ensure the directory exists\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    107\u001b[39m     f.write(md)\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSUCESSFULLY PARSED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbib_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m'\u001b[39m, b[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m60\u001b[39m],\u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m*(\u001b[38;5;28mlen\u001b[39m(b[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m])>\u001b[32m60\u001b[39m),\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../_publications/2024-01-01-Classification-of-skin-lesion-with-features-extraction-using-quantum-chebyshev-polynomials-and-autoencoder-from-wavelet-transformed-images.md'"
     ]
    }
   ],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "from time import strptime\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "\n",
    "for pubsource in publist:\n",
    "    bibfile = publist[pubsource][\"file\"]\n",
    "    if not os.path.isfile(bibfile):\n",
    "        print(f\"WARNING: File '{bibfile}' not found. Skipping.\")\n",
    "        continue\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(bibfile)\n",
    "\n",
    "    # loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        # reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "\n",
    "        b = bibdata.entries[bib_id].fields\n",
    "\n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            # todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys():\n",
    "                if len(b[\"month\"]) < 3:\n",
    "                    pub_month = \"0\" + b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif not b[\"month\"].isdigit():\n",
    "                    tmnth = strptime(b[\"month\"][:3], '%b').tm_mon\n",
    "                    pub_month = \"{:02d}\".format(tmnth)\n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys():\n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "            pub_date = pub_year + \"-\" + pub_month + \"-\" + pub_day\n",
    "\n",
    "            # strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"\\\\\", \"\").replace(\" \", \"-\")\n",
    "\n",
    "            url_slug = re.sub(r\"\\[.*\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\", \"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\", \"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\", \"-\")\n",
    "\n",
    "            # Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            # citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                first = author.first_names[0] if author.first_names else \"\"\n",
    "                last = author.last_names[0] if author.last_names else \"\"\n",
    "                citation = citation + \" \" + first + \" \" + last + \", \"\n",
    "\n",
    "            # citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"\\\\\", \"\")) + \".\\\"\"\n",
    "\n",
    "            # add venue logic depending on citation type\n",
    "            venue = \"\"\n",
    "            try:\n",
    "                venue = publist[pubsource][\"venue-pretext\"] + b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"\\\\\", \"\")\n",
    "            except KeyError:\n",
    "                venue = \"\"\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"\\\\\", \"\")) + '\\\"\\n'\n",
    "            md += \"collection: \" + publist[pubsource][\"collection\"][\"name\"]\n",
    "            md += \"\\npermalink: \" + publist[pubsource][\"collection\"][\"permalink\"] + html_filename\n",
    "\n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date)\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "\n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += f\"\\n[Access paper here]({b['url']})\" + \"{:target=\\\"_blank\\\"}\\n\"\n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\" + html.escape(clean_title.replace(\"-\", \"+\")) + \"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            output_dir = \"../_publications/\"\n",
    "            os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "            with open(os.path.join(output_dir, md_filename), 'w', encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60], \"...\"*(len(b['title'])>60), \"\\\"\")\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b.get(\"title\", \"NO TITLE\")[:30], \"...\"*(len(b.get('title', \"\"))>30), \"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
